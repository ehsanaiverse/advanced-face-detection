{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f00ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "class AdvancedFaceDetectionSystem:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe components\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "        # MediaPipe Face Detection (more accurate than Haar cascades)\n",
    "        self.face_detection = self.mp_face_detection.FaceDetection(\n",
    "            model_selection=0,  # 0 for close-range (2m), 1 for full-range (5m)\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # MediaPipe Face Mesh (468 landmarks)\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=5,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Age/Gender Detection Models\n",
    "        self.age_net = None\n",
    "        self.gender_net = None\n",
    "        self.load_age_gender_models()\n",
    "        \n",
    "        # Feature toggles\n",
    "        self.show_landmarks = False\n",
    "        self.show_age_gender = False\n",
    "        self.show_confidence = True\n",
    "        self.show_face_mesh = False\n",
    "        \n",
    "        # AR Filter system\n",
    "        self.current_filter = \"none\"  # none, sunglasses, mustache, hat\n",
    "        self.create_ar_filters()\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.fps_counter = deque(maxlen=30)\n",
    "        self.frame_count = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        # Age and gender lists\n",
    "        self.age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "        self.gender_list = ['Male', 'Female']\n",
    "    \n",
    "    def load_age_gender_models(self):\n",
    "        \"\"\"Load pre-downloaded age and gender detection models\"\"\"\n",
    "        try:\n",
    "            # Load age detection model\n",
    "            if os.path.exists('models/age_net.caffemodel') and os.path.exists('models/age_deploy.prototxt'):\n",
    "                self.age_net = cv2.dnn.readNet('models/age_net.caffemodel', 'models/age_deploy.prototxt')\n",
    "                print(\"‚úÖ Age detection model loaded successfully\")\n",
    "            else:\n",
    "                print(\"‚ùå Age model files not found in models/ directory\")\n",
    "            \n",
    "            # Load gender detection model  \n",
    "            if os.path.exists('models/gender_net.caffemodel') and os.path.exists('models/gender_deploy.prototxt'):\n",
    "                self.gender_net = cv2.dnn.readNet('models/gender_net.caffemodel', 'models/gender_deploy.prototxt')\n",
    "                print(\"‚úÖ Gender detection model loaded successfully\")\n",
    "            else:\n",
    "                print(\"‚ùå Gender model files not found in models/ directory\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading age/gender models: {e}\")\n",
    "            print(\"Make sure model files are in the 'models/' directory\")\n",
    "    \n",
    "    def create_ar_filters(self):\n",
    "        \"\"\"Create AR filter assets\"\"\"\n",
    "        # Create sunglasses filter\n",
    "        self.sunglasses = np.zeros((50, 150, 4), dtype=np.uint8)\n",
    "        cv2.rectangle(self.sunglasses, (0, 0), (149, 49), (0, 0, 0, 200), -1)  # Dark lenses\n",
    "        cv2.rectangle(self.sunglasses, (0, 0), (149, 49), (255, 255, 255, 255), 3)  # White frame\n",
    "        cv2.line(self.sunglasses, (75, 20), (75, 30), (255, 255, 255, 255), 4)  # Bridge\n",
    "        \n",
    "        # Create mustache filter\n",
    "        self.mustache = np.zeros((40, 100, 4), dtype=np.uint8)\n",
    "        cv2.ellipse(self.mustache, (50, 25), (45, 15), 0, 0, 180, (101, 67, 33, 255), -1)\n",
    "        cv2.ellipse(self.mustache, (50, 25), (45, 15), 0, 0, 180, (139, 90, 43, 255), 3)\n",
    "        \n",
    "        # Create hat filter\n",
    "        self.hat = np.zeros((80, 120, 4), dtype=np.uint8)\n",
    "        cv2.rectangle(self.hat, (10, 60), (110, 75), (255, 0, 0, 255), -1)  # Hat brim\n",
    "        cv2.rectangle(self.hat, (25, 10), (95, 65), (139, 0, 0, 255), -1)   # Hat top\n",
    "        \n",
    "        print(\"‚úÖ AR filters created successfully\")\n",
    "    \n",
    "    def detect_faces_mediapipe(self, frame):\n",
    "        \"\"\"Advanced face detection using MediaPipe\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_detection.process(rgb_frame)\n",
    "        \n",
    "        faces = []\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                # Get bounding box\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = frame.shape\n",
    "                \n",
    "                x = max(0, int(bbox.xmin * w))\n",
    "                y = max(0, int(bbox.ymin * h))\n",
    "                width = min(w - x, int(bbox.width * w))\n",
    "                height = min(h - y, int(bbox.height * h))\n",
    "                \n",
    "                # Get confidence score\n",
    "                confidence = detection.score[0]\n",
    "                \n",
    "                faces.append({\n",
    "                    'bbox': (x, y, width, height),\n",
    "                    'confidence': confidence,\n",
    "                    'keypoints': self.extract_face_keypoints(detection, w, h)\n",
    "                })\n",
    "        \n",
    "        return faces\n",
    "    \n",
    "    def extract_face_keypoints(self, detection, frame_width, frame_height):\n",
    "        \"\"\"Extract facial keypoints from MediaPipe detection\"\"\"\n",
    "        keypoints = {}\n",
    "        if detection.location_data.relative_keypoints:\n",
    "            keypoint_names = ['right_eye', 'left_eye', 'nose_tip', 'mouth_center', 'right_ear', 'left_ear']\n",
    "            for i, keypoint in enumerate(detection.location_data.relative_keypoints):\n",
    "                if i < len(keypoint_names):\n",
    "                    keypoints[keypoint_names[i]] = (\n",
    "                        int(keypoint.x * frame_width),\n",
    "                        int(keypoint.y * frame_height)\n",
    "                    )\n",
    "        return keypoints\n",
    "    \n",
    "    def get_facial_landmarks(self, frame):\n",
    "        \"\"\"Get 468 facial landmarks using MediaPipe Face Mesh\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        landmarks_data = []\n",
    "        if results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                landmarks = []\n",
    "                for landmark in face_landmarks.landmark:\n",
    "                    x = int(landmark.x * w)\n",
    "                    y = int(landmark.y * h)\n",
    "                    landmarks.append((x, y))\n",
    "                landmarks_data.append(landmarks)\n",
    "        \n",
    "        return landmarks_data, results\n",
    "    \n",
    "    def predict_age_gender(self, face_roi):\n",
    "        \"\"\"Predict age and gender using CNN models\"\"\"\n",
    "        if self.age_net is None or self.gender_net is None:\n",
    "            return \"Model Error\", \"Model Error\", 0.0\n",
    "        \n",
    "        if face_roi.size == 0:\n",
    "            return \"Invalid Face\", \"Invalid Face\", 0.0\n",
    "        \n",
    "        try:\n",
    "            # Preprocess face region\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                face_roi, 1.0, (227, 227),\n",
    "                (78.4263377603, 87.7689143744, 114.895847746)\n",
    "            )\n",
    "            \n",
    "            # Age prediction\n",
    "            self.age_net.setInput(blob)\n",
    "            age_predictions = self.age_net.forward()\n",
    "            age_idx = age_predictions[0].argmax()\n",
    "            age_confidence = age_predictions[0].max()\n",
    "            predicted_age = self.age_list[age_idx]\n",
    "            \n",
    "            # Gender prediction\n",
    "            self.gender_net.setInput(blob)\n",
    "            gender_predictions = self.gender_net.forward()\n",
    "            gender_idx = gender_predictions[0].argmax()\n",
    "            gender_confidence = gender_predictions[0].max()\n",
    "            predicted_gender = self.gender_list[gender_idx]\n",
    "            \n",
    "            # Combined confidence\n",
    "            combined_confidence = (age_confidence + gender_confidence) / 2\n",
    "            \n",
    "            return predicted_age, predicted_gender, combined_confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            return \"Error\", \"Error\", 0.0\n",
    "    \n",
    "    def apply_sunglasses_filter(self, frame, landmarks):\n",
    "        \"\"\"Apply sunglasses AR filter based on facial landmarks\"\"\"\n",
    "        if len(landmarks) < 468:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get eye positions (MediaPipe landmark indices)\n",
    "            left_eye_center = landmarks[33]   # Left eye center\n",
    "            right_eye_center = landmarks[362] # Right eye center\n",
    "            \n",
    "            # Calculate sunglasses parameters\n",
    "            eye_distance = math.sqrt(\n",
    "                (right_eye_center[0] - left_eye_center[0])**2 + \n",
    "                (right_eye_center[1] - left_eye_center[1])**2\n",
    "            )\n",
    "            \n",
    "            # Calculate center point between eyes\n",
    "            center_x = (left_eye_center[0] + right_eye_center[0]) // 2\n",
    "            center_y = (left_eye_center[1] + right_eye_center[1]) // 2\n",
    "            \n",
    "            # Scale sunglasses based on eye distance\n",
    "            scale_factor = eye_distance / 100\n",
    "            new_width = int(self.sunglasses.shape[1] * scale_factor)\n",
    "            new_height = int(self.sunglasses.shape[0] * scale_factor)\n",
    "            \n",
    "            if new_width > 10 and new_height > 10:\n",
    "                # Resize sunglasses\n",
    "                resized_sunglasses = cv2.resize(self.sunglasses, (new_width, new_height))\n",
    "                \n",
    "                # Calculate position\n",
    "                start_x = center_x - new_width // 2\n",
    "                start_y = center_y - new_height // 2\n",
    "                \n",
    "                # Apply overlay\n",
    "                self.overlay_image_alpha(frame, resized_sunglasses, start_x, start_y)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Sunglasses filter error: {e}\")\n",
    "    \n",
    "    def apply_mustache_filter(self, frame, landmarks):\n",
    "        \"\"\"Apply mustache AR filter\"\"\"\n",
    "        if len(landmarks) < 468:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get nose and mouth positions\n",
    "            nose_bottom = landmarks[2]    # Nose bottom\n",
    "            mouth_top = landmarks[12]     # Mouth top\n",
    "            \n",
    "            # Calculate mustache position\n",
    "            mustache_center_x = (nose_bottom[0] + mouth_top[0]) // 2\n",
    "            mustache_center_y = (nose_bottom[1] + mouth_top[1]) // 2\n",
    "            \n",
    "            # Scale based on face width\n",
    "            face_width = abs(landmarks[454][0] - landmarks[234][0])  # Face contour points\n",
    "            scale_factor = face_width / 200\n",
    "            \n",
    "            new_width = int(self.mustache.shape[1] * scale_factor)\n",
    "            new_height = int(self.mustache.shape[0] * scale_factor)\n",
    "            \n",
    "            if new_width > 10 and new_height > 10:\n",
    "                resized_mustache = cv2.resize(self.mustache, (new_width, new_height))\n",
    "                \n",
    "                start_x = mustache_center_x - new_width // 2\n",
    "                start_y = mustache_center_y - new_height // 2\n",
    "                \n",
    "                self.overlay_image_alpha(frame, resized_mustache, start_x, start_y)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Mustache filter error: {e}\")\n",
    "    \n",
    "    def apply_hat_filter(self, frame, landmarks):\n",
    "        \"\"\"Apply hat AR filter\"\"\"\n",
    "        if len(landmarks) < 468:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get forehead position\n",
    "            forehead_center = landmarks[10]  # Forehead center\n",
    "            \n",
    "            # Calculate hat position\n",
    "            face_width = abs(landmarks[454][0] - landmarks[234][0])\n",
    "            scale_factor = face_width / 150\n",
    "            \n",
    "            new_width = int(self.hat.shape[1] * scale_factor)\n",
    "            new_height = int(self.hat.shape[0] * scale_factor)\n",
    "            \n",
    "            if new_width > 10 and new_height > 10:\n",
    "                resized_hat = cv2.resize(self.hat, (new_width, new_height))\n",
    "                \n",
    "                start_x = forehead_center[0] - new_width // 2\n",
    "                start_y = forehead_center[1] - new_height\n",
    "                \n",
    "                self.overlay_image_alpha(frame, resized_hat, start_x, start_y)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Hat filter error: {e}\")\n",
    "    \n",
    "    def overlay_image_alpha(self, background, overlay, x, y):\n",
    "        \"\"\"Overlay image with alpha channel onto background\"\"\"\n",
    "        if overlay.shape[2] != 4:\n",
    "            return\n",
    "        \n",
    "        h, w = overlay.shape[:2]\n",
    "        \n",
    "        # Ensure overlay is within frame bounds\n",
    "        if x < 0 or y < 0 or x + w > background.shape[1] or y + h > background.shape[0]:\n",
    "            return\n",
    "        \n",
    "        # Extract alpha channel\n",
    "        alpha = overlay[:, :, 3] / 255.0\n",
    "        \n",
    "        # Apply overlay for each color channel\n",
    "        for c in range(3):\n",
    "            background[y:y+h, x:x+w, c] = (\n",
    "                alpha * overlay[:, :, c] + \n",
    "                (1 - alpha) * background[y:y+h, x:x+w, c]\n",
    "            )\n",
    "    \n",
    "    def draw_landmarks(self, frame, landmarks):\n",
    "        \"\"\"Draw 468 facial landmarks\"\"\"\n",
    "        for point in landmarks:\n",
    "            cv2.circle(frame, point, 1, (0, 255, 0), -1)\n",
    "    \n",
    "    def draw_face_mesh(self, frame, face_mesh_results):\n",
    "        \"\"\"Draw 3D face mesh\"\"\"\n",
    "        if face_mesh_results.multi_face_landmarks:\n",
    "            for face_landmarks in face_mesh_results.multi_face_landmarks:\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    frame, \n",
    "                    face_landmarks,\n",
    "                    self.mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    None,\n",
    "                    self.mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "                )\n",
    "    \n",
    "    def draw_ui_controls(self, frame):\n",
    "        \"\"\"Draw UI controls and information\"\"\"\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Create semi-transparent overlay for controls\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (10, height-150), (400, height-10), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Control instructions\n",
    "        controls = [\n",
    "            \"CONTROLS:\",\n",
    "            \"S - Toggle Sunglasses\",\n",
    "            \"M - Toggle Mustache\", \n",
    "            \"H - Toggle Hat\",\n",
    "            \"L - Toggle Landmarks\",\n",
    "            \"F - Toggle Face Mesh\",\n",
    "            \"A - Toggle Age/Gender\",\n",
    "            \"C - Toggle Confidence\",\n",
    "            \"Q - Quit\"\n",
    "        ]\n",
    "        \n",
    "        for i, control in enumerate(controls):\n",
    "            color = (0, 255, 255) if i == 0 else (255, 255, 255)\n",
    "            cv2.putText(frame, control, (15, height-140+i*15), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "        \n",
    "        # Status display\n",
    "        status_y = 30\n",
    "        status_info = [\n",
    "            f\"Filter: {self.current_filter}\",\n",
    "            f\"Landmarks: {'ON' if self.show_landmarks else 'OFF'}\",\n",
    "            f\"Age/Gender: {'ON' if self.show_age_gender else 'OFF'}\",\n",
    "            f\"FPS: {np.mean(self.fps_counter):.1f}\" if self.fps_counter else \"FPS: --\"\n",
    "        ]\n",
    "        \n",
    "        for i, status in enumerate(status_info):\n",
    "            cv2.putText(frame, status, (width-200, status_y+i*25), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame with all features\"\"\"\n",
    "        frame_start = time.time()\n",
    "        \n",
    "        # 1. Detect faces using MediaPipe\n",
    "        faces = self.detect_faces_mediapipe(frame)\n",
    "        \n",
    "        # 2. Get facial landmarks\n",
    "        landmarks_data, face_mesh_results = self.get_facial_landmarks(frame)\n",
    "        \n",
    "        # 3. Process each detected face\n",
    "        for i, face in enumerate(faces):\n",
    "            x, y, w, h = face['bbox']\n",
    "            confidence = face['confidence']\n",
    "            \n",
    "            # Draw face bounding box\n",
    "            color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255)\n",
    "            thickness = 2 if confidence > 0.7 else 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)\n",
    "            \n",
    "            # Show confidence if enabled\n",
    "            if self.show_confidence:\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', \n",
    "                          (x, y-30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            \n",
    "            # Age and gender prediction\n",
    "            if self.show_age_gender:\n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                if face_roi.size > 0:\n",
    "                    age, gender, ag_confidence = self.predict_age_gender(face_roi)\n",
    "                    text = f'{gender}, {age}'\n",
    "                    cv2.putText(frame, text, (x, y-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    \n",
    "                    if self.show_confidence:\n",
    "                        cv2.putText(frame, f'A/G Conf: {ag_confidence:.2f}', \n",
    "                                  (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "        \n",
    "        # 4. Apply AR filters and landmarks\n",
    "        if landmarks_data:\n",
    "            for landmarks in landmarks_data:\n",
    "                # Show landmarks if enabled\n",
    "                if self.show_landmarks:\n",
    "                    self.draw_landmarks(frame, landmarks)\n",
    "                \n",
    "                # Apply AR filters\n",
    "                if self.current_filter == \"sunglasses\":\n",
    "                    self.apply_sunglasses_filter(frame, landmarks)\n",
    "                elif self.current_filter == \"mustache\":\n",
    "                    self.apply_mustache_filter(frame, landmarks)\n",
    "                elif self.current_filter == \"hat\":\n",
    "                    self.apply_hat_filter(frame, landmarks)\n",
    "        \n",
    "        # 5. Show face mesh if enabled\n",
    "        if self.show_face_mesh:\n",
    "            self.draw_face_mesh(frame, face_mesh_results)\n",
    "        \n",
    "        # 6. Draw UI controls\n",
    "        self.draw_ui_controls(frame)\n",
    "        \n",
    "        # Update FPS\n",
    "        frame_time = time.time() - frame_start\n",
    "        if frame_time > 0:\n",
    "            self.fps_counter.append(1.0 / frame_time)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def run_detection(self):\n",
    "        \"\"\"Main detection loop\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        print(\"üöÄ Advanced Face Detection System Started!\")\n",
    "        print(\"üéØ Features: MediaPipe Detection | 468 Landmarks | Age/Gender | AR Filters\")\n",
    "        print(\"üìã Press keys to toggle features (see on-screen controls)\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to read from camera\")\n",
    "                break\n",
    "            \n",
    "            # Process frame with all features\n",
    "            frame = self.process_frame(frame)\n",
    "            \n",
    "            # Display frame\n",
    "            cv2.imshow('Advanced Face Detection System', frame)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                self.current_filter = \"sunglasses\" if self.current_filter != \"sunglasses\" else \"none\"\n",
    "                print(f\"Filter: {self.current_filter}\")\n",
    "            elif key == ord('m'):\n",
    "                self.current_filter = \"mustache\" if self.current_filter != \"mustache\" else \"none\"\n",
    "                print(f\"Filter: {self.current_filter}\")\n",
    "            elif key == ord('h'):\n",
    "                self.current_filter = \"hat\" if self.current_filter != \"hat\" else \"none\"\n",
    "                print(f\"Filter: {self.current_filter}\")\n",
    "            elif key == ord('l'):\n",
    "                self.show_landmarks = not self.show_landmarks\n",
    "                print(f\"Landmarks: {'ON' if self.show_landmarks else 'OFF'}\")\n",
    "            elif key == ord('f'):\n",
    "                self.show_face_mesh = not self.show_face_mesh\n",
    "                print(f\"Face Mesh: {'ON' if self.show_face_mesh else 'OFF'}\")\n",
    "            elif key == ord('a'):\n",
    "                self.show_age_gender = not self.show_age_gender\n",
    "                print(f\"Age/Gender: {'ON' if self.show_age_gender else 'OFF'}\")\n",
    "            elif key == ord('c'):\n",
    "                self.show_confidence = not self.show_confidence\n",
    "                print(f\"Confidence: {'ON' if self.show_confidence else 'OFF'}\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Print session summary\n",
    "        total_time = time.time() - self.start_time\n",
    "        avg_fps = np.mean(self.fps_counter) if self.fps_counter else 0\n",
    "        print(f\"\\nüìä Session Summary:\")\n",
    "        print(f\"   Duration: {total_time:.1f}s\")\n",
    "        print(f\"   Average FPS: {avg_fps:.1f}\")\n",
    "        print(f\"   Total Frames: {self.frame_count}\")\n",
    "\n",
    "# USAGE\n",
    "if __name__ == \"__main__\":\n",
    "    # Create and run the advanced face detection system\n",
    "    system = AdvancedFaceDetectionSystem()\n",
    "    system.run_detection()\n",
    "\n",
    "\"\"\"\n",
    "üéØ FEATURES IMPLEMENTED:\n",
    "\n",
    "‚úÖ MediaPipe Face Detection (10x more accurate than Haar cascades)\n",
    "‚úÖ Real-time confidence scores for each detection\n",
    "‚úÖ 468 facial landmarks with precise tracking\n",
    "‚úÖ Age & Gender detection using CNN models\n",
    "‚úÖ 3D face mesh visualization\n",
    "‚úÖ AR Filters: Sunglasses, Mustache, Hat\n",
    "‚úÖ Interactive controls with real-time switching\n",
    "‚úÖ Performance monitoring (FPS tracking)\n",
    "‚úÖ Alpha blending for realistic filter effects\n",
    "‚úÖ Adaptive filter sizing based on face dimensions\n",
    "\n",
    "üéÆ CONTROLS:\n",
    "S - Toggle Sunglasses Filter\n",
    "M - Toggle Mustache Filter  \n",
    "H - Toggle Hat Filter\n",
    "L - Show/Hide 468 Landmarks\n",
    "F - Toggle 3D Face Mesh\n",
    "A - Enable/Disable Age/Gender Detection\n",
    "C - Show/Hide Confidence Scores\n",
    "Q - Quit Application\n",
    "\n",
    "üîß REQUIREMENTS:\n",
    "- Place age/gender models in 'models/' directory:\n",
    "  * age_net.caffemodel\n",
    "  * age_deploy.prototxt  \n",
    "  * gender_net.caffemodel\n",
    "  * gender_deploy.prototxt\n",
    "\n",
    "üì¶ INSTALL:\n",
    "pip install opencv-python mediapipe numpy\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
