{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a25b47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AR Filter assets loaded!\n",
      "âš ï¸ Age/Gender models not found. Download from OpenCV model zoo.\n",
      "ðŸš€ Advanced AI Face Detection Started!\n",
      "Controls:\n",
      "  's' - Toggle sunglasses filter\n",
      "  'l' - Toggle landmarks\n",
      "  'a' - Toggle age/gender detection\n",
      "  'q' - Quit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nðŸŽ¯ MORE ADVANCED FEATURES TO IMPLEMENT:\\n\\n1. REAL-TIME EMOTION RECOGNITION:\\n  - Use TensorFlow/PyTorch emotion models\\n  - Detect: Happy, Sad, Angry, Surprised, Fearful, Disgusted, Neutral\\n\\n2. FACE RECOGNITION & IDENTIFICATION:\\n  - Use face_recognition library\\n  - Save known faces to database\\n  - Real-time identification with names\\n\\n3. ADVANCED AR FILTERS:\\n  - Load custom 3D models\\n  - Animal face morphing\\n  - Background replacement (green screen effect)\\n\\n4. GESTURE-CONTROLLED INTERFACE:\\n  - Hand tracking with MediaPipe\\n  - Control filters with hand gestures\\n  - Voice commands integration\\n\\n5. SOCIAL MEDIA INTEGRATION:\\n  - Save filtered photos/videos\\n  - Share to Instagram/TikTok\\n  - Live streaming with filters\\n\\n6. PERFORMANCE ANALYTICS:\\n  - Face detection accuracy metrics\\n  - FPS optimization\\n  - Memory usage monitoring\\n\\n7. MULTI-PERSON FEATURES:\\n  - Individual filters per person\\n  - Face swapping between people\\n  - Group photo enhancements\\n\\nTo implement these, install additional packages:\\npip install face-recognition tensorflow torch ultralytics\\npip install streamlit (for web interface)\\npip install opencv-contrib-python (for advanced features)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI-POWERED & AUGMENTED REALITY FACE DETECTION\n",
    "# Advanced features to make your project stand out\n",
    "\n",
    "# ==================================================\n",
    "# SECTION 1: AI-POWERED UPGRADES\n",
    "# ==================================================\n",
    "\n",
    "# Required installations:\n",
    "# pip install mediapipe tensorflow opencv-contrib-python dlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1.1 MODERN FACE DETECTION WITH MEDIAPIPE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class AIFaceDetector:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe Face Detection (more accurate than Haar cascades)\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.face_detection = self.mp_face_detection.FaceDetection(\n",
    "            model_selection=0,  # 0 for close-range, 1 for full-range\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Initialize MediaPipe Face Mesh for detailed landmarks\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=5,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def detect_faces_ai(self, frame):\n",
    "        \"\"\"Advanced AI-powered face detection\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_detection.process(rgb_frame)\n",
    "        \n",
    "        faces = []\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                # Get bounding box\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = frame.shape\n",
    "                \n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "                \n",
    "                # Get confidence score\n",
    "                confidence = detection.score[0]\n",
    "                \n",
    "                faces.append({\n",
    "                    'bbox': (x, y, width, height),\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "                \n",
    "                # Draw detection\n",
    "                cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', \n",
    "                            (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        return frame, faces\n",
    "\n",
    "    def detect_facial_landmarks(self, frame):\n",
    "        \"\"\"Detect 468 facial landmarks for precise tracking\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Draw face mesh\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    frame, face_landmarks, self.mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    None, self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "                )\n",
    "                \n",
    "                # Extract key points\n",
    "                h, w, _ = frame.shape\n",
    "                landmarks = []\n",
    "                for landmark in face_landmarks.landmark:\n",
    "                    x = int(landmark.x * w)\n",
    "                    y = int(landmark.y * h)\n",
    "                    landmarks.append((x, y))\n",
    "                \n",
    "                # Highlight key facial features\n",
    "                self.highlight_facial_features(frame, landmarks)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def highlight_facial_features(self, frame, landmarks):\n",
    "        \"\"\"Highlight eyes, nose, and mouth\"\"\"\n",
    "        if len(landmarks) >= 468:\n",
    "            # Eye regions (approximate indices)\n",
    "            left_eye = landmarks[33]  # Left eye center\n",
    "            right_eye = landmarks[362]  # Right eye center\n",
    "            nose_tip = landmarks[1]   # Nose tip\n",
    "            mouth_center = landmarks[13]  # Mouth center\n",
    "            \n",
    "            # Draw feature points\n",
    "            features = [\n",
    "                (left_eye, \"L_Eye\", (255, 0, 0)),\n",
    "                (right_eye, \"R_Eye\", (255, 0, 0)),\n",
    "                (nose_tip, \"Nose\", (0, 255, 255)),\n",
    "                (mouth_center, \"Mouth\", (0, 0, 255))\n",
    "            ]\n",
    "            \n",
    "            for point, label, color in features:\n",
    "                cv2.circle(frame, point, 5, color, -1)\n",
    "                cv2.putText(frame, label, (point[0]+10, point[1]), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1.2 AGE AND GENDER DETECTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class AgeGenderDetector:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained models (you need to download these)\n",
    "        self.age_net = None\n",
    "        self.gender_net = None\n",
    "        self.load_models()\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load age and gender detection models\"\"\"\n",
    "        try:\n",
    "            # Age detection model\n",
    "            age_weights = \"age_net.caffemodel\"  # Download from OpenCV model zoo\n",
    "            age_config = \"age_deploy.prototxt\"\n",
    "            self.age_net = cv2.dnn.readNet(age_weights, age_config)\n",
    "            \n",
    "            # Gender detection model\n",
    "            gender_weights = \"gender_net.caffemodel\"\n",
    "            gender_config = \"gender_deploy.prototxt\"\n",
    "            self.gender_net = cv2.dnn.readNet(gender_weights, gender_config)\n",
    "            \n",
    "            print(\"âœ… Age and Gender models loaded successfully!\")\n",
    "        except:\n",
    "            print(\"âš ï¸ Age/Gender models not found. Download from OpenCV model zoo.\")\n",
    "    \n",
    "    def predict_age_gender(self, face_roi):\n",
    "        \"\"\"Predict age and gender for a face region\"\"\"\n",
    "        if self.age_net is None or self.gender_net is None:\n",
    "            return \"Unknown\", \"Unknown\"\n",
    "        \n",
    "        # Preprocess face\n",
    "        blob = cv2.dnn.blobFromImage(face_roi, 1.0, (227, 227), \n",
    "                                    (78.4263377603, 87.7689143744, 114.895847746))\n",
    "        \n",
    "        # Age prediction\n",
    "        self.age_net.setInput(blob)\n",
    "        age_predictions = self.age_net.forward()\n",
    "        age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "        predicted_age = age_list[age_predictions[0].argmax()]\n",
    "        \n",
    "        # Gender prediction\n",
    "        self.gender_net.setInput(blob)\n",
    "        gender_predictions = self.gender_net.forward()\n",
    "        gender_list = ['Male', 'Female']\n",
    "        predicted_gender = gender_list[gender_predictions[0].argmax()]\n",
    "        \n",
    "        return predicted_age, predicted_gender\n",
    "\n",
    "# ==================================================\n",
    "# SECTION 2: AUGMENTED REALITY FEATURES\n",
    "# ==================================================\n",
    "\n",
    "class ARFaceFilters:\n",
    "    def __init__(self):\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Load filter assets (you can create these or download)\n",
    "        self.load_filter_assets()\n",
    "    \n",
    "    def load_filter_assets(self):\n",
    "        \"\"\"Load virtual mask and filter images\"\"\"\n",
    "        try:\n",
    "            # Create simple virtual elements\n",
    "            self.sunglasses = self.create_sunglasses()\n",
    "            self.mustache = self.create_mustache()\n",
    "            self.hat = self.create_hat()\n",
    "            print(\"âœ… AR Filter assets loaded!\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Filter assets error: {e}\")\n",
    "    \n",
    "    def create_sunglasses(self):\n",
    "        \"\"\"Create a simple sunglasses overlay\"\"\"\n",
    "        # Create a simple black rectangle for sunglasses\n",
    "        sunglasses = np.zeros((40, 120, 4), dtype=np.uint8)  # RGBA\n",
    "        sunglasses[:, :, :3] = [0, 0, 0]  # Black\n",
    "        sunglasses[:, :, 3] = 200  # Semi-transparent\n",
    "        \n",
    "        # Add white frame\n",
    "        cv2.rectangle(sunglasses, (0, 0), (119, 39), (255, 255, 255, 255), 2)\n",
    "        cv2.line(sunglasses, (60, 20), (60, 20), (255, 255, 255, 255), 3)  # Bridge\n",
    "        \n",
    "        return sunglasses\n",
    "    \n",
    "    def create_mustache(self):\n",
    "        \"\"\"Create a simple mustache overlay\"\"\"\n",
    "        mustache = np.zeros((30, 80, 4), dtype=np.uint8)\n",
    "        # Draw mustache shape\n",
    "        cv2.ellipse(mustache, (40, 15), (35, 10), 0, 0, 180, (101, 67, 33, 255), -1)\n",
    "        return mustache\n",
    "    \n",
    "    def create_hat(self):\n",
    "        \"\"\"Create a simple hat overlay\"\"\"\n",
    "        hat = np.zeros((60, 100, 4), dtype=np.uint8)\n",
    "        cv2.rectangle(hat, (10, 40), (90, 55), (255, 0, 0, 255), -1)  # Hat brim\n",
    "        cv2.rectangle(hat, (25, 10), (75, 45), (0, 0, 255, 255), -1)   # Hat top\n",
    "        return hat\n",
    "    \n",
    "    def apply_sunglasses_filter(self, frame, landmarks):\n",
    "        \"\"\"Apply sunglasses to detected face\"\"\"\n",
    "        if len(landmarks) >= 468:\n",
    "            # Get eye positions\n",
    "            left_eye = landmarks[33]\n",
    "            right_eye = landmarks[362]\n",
    "            \n",
    "            # Calculate sunglasses position and size\n",
    "            eye_distance = int(math.sqrt((right_eye[0] - left_eye[0])**2 + \n",
    "                                        (right_eye[1] - left_eye[1])**2))\n",
    "            \n",
    "            center_x = (left_eye[0] + right_eye[0]) // 2\n",
    "            center_y = (left_eye[1] + right_eye[1]) // 2\n",
    "            \n",
    "            # Resize sunglasses based on face size\n",
    "            scale = eye_distance / 60  # Adjust scale factor\n",
    "            new_width = int(self.sunglasses.shape[1] * scale)\n",
    "            new_height = int(self.sunglasses.shape[0] * scale)\n",
    "            \n",
    "            if new_width > 0 and new_height > 0:\n",
    "                resized_glasses = cv2.resize(self.sunglasses, (new_width, new_height))\n",
    "                \n",
    "                # Position sunglasses\n",
    "                start_x = center_x - new_width // 2\n",
    "                start_y = center_y - new_height // 2\n",
    "                \n",
    "                # Apply overlay\n",
    "                self.overlay_image(frame, resized_glasses, start_x, start_y)\n",
    "    \n",
    "    def overlay_image(self, background, overlay, x, y):\n",
    "        \"\"\"Overlay image with alpha channel onto background\"\"\"\n",
    "        if overlay.shape[2] == 4:  # RGBA\n",
    "            h, w = overlay.shape[:2]\n",
    "            \n",
    "            # Ensure overlay fits within frame\n",
    "            if x + w <= background.shape[1] and y + h <= background.shape[0] and x >= 0 and y >= 0:\n",
    "                # Extract alpha channel\n",
    "                alpha = overlay[:, :, 3] / 255.0\n",
    "                \n",
    "                # Apply overlay\n",
    "                for c in range(3):  # RGB channels\n",
    "                    background[y:y+h, x:x+w, c] = (\n",
    "                        alpha * overlay[:, :, c] + \n",
    "                        (1 - alpha) * background[y:y+h, x:x+w, c]\n",
    "                    )\n",
    "\n",
    "# ==================================================\n",
    "# SECTION 3: COMBINED DEMO APPLICATION\n",
    "# ==================================================\n",
    "\n",
    "class AdvancedFaceApp:\n",
    "    def __init__(self):\n",
    "        self.ai_detector = AIFaceDetector()\n",
    "        self.ar_filters = ARFaceFilters()\n",
    "        self.age_gender = AgeGenderDetector()\n",
    "        \n",
    "        self.current_filter = \"none\"  # none, sunglasses, mustache, hat\n",
    "        self.show_landmarks = False\n",
    "        self.show_age_gender = False\n",
    "    \n",
    "    def run_advanced_detection(self):\n",
    "        \"\"\"Run the complete advanced face detection application\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        print(\"ðŸš€ Advanced AI Face Detection Started!\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  's' - Toggle sunglasses filter\")\n",
    "        print(\"  'l' - Toggle landmarks\")\n",
    "        print(\"  'a' - Toggle age/gender detection\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # AI-powered face detection\n",
    "            frame, faces = self.ai_detector.detect_faces_ai(frame)\n",
    "            \n",
    "            # Get facial landmarks for AR filters\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.ar_filters.face_mesh.process(rgb_frame)\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # Convert landmarks to pixel coordinates\n",
    "                    h, w, _ = frame.shape\n",
    "                    landmarks = []\n",
    "                    for landmark in face_landmarks.landmark:\n",
    "                        x = int(landmark.x * w)\n",
    "                        y = int(landmark.y * h)\n",
    "                        landmarks.append((x, y))\n",
    "                    \n",
    "                    # Apply AR filters\n",
    "                    if self.current_filter == \"sunglasses\":\n",
    "                        self.ar_filters.apply_sunglasses_filter(frame, landmarks)\n",
    "                    \n",
    "                    # Show landmarks if enabled\n",
    "                    if self.show_landmarks:\n",
    "                        for point in landmarks[::5]:  # Show every 5th landmark\n",
    "                            cv2.circle(frame, point, 1, (0, 255, 0), -1)\n",
    "            \n",
    "            # Show age and gender if enabled\n",
    "            if self.show_age_gender and faces:\n",
    "                for face in faces:\n",
    "                    x, y, w, h = face['bbox']\n",
    "                    face_roi = frame[y:y+h, x:x+w]\n",
    "                    if face_roi.size > 0:\n",
    "                        age, gender = self.age_gender.predict_age_gender(face_roi)\n",
    "                        cv2.putText(frame, f\"{gender}, {age}\", (x, y-30), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "            \n",
    "            # Display controls on screen\n",
    "            cv2.putText(frame, f\"Filter: {self.current_filter}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Advanced AI Face Detection with AR', frame)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                self.current_filter = \"sunglasses\" if self.current_filter != \"sunglasses\" else \"none\"\n",
    "            elif key == ord('l'):\n",
    "                self.show_landmarks = not self.show_landmarks\n",
    "            elif key == ord('a'):\n",
    "                self.show_age_gender = not self.show_age_gender\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ==================================================\n",
    "# USAGE EXAMPLE\n",
    "# ==================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the advanced application\n",
    "    app = AdvancedFaceApp()\n",
    "    app.run_advanced_detection()\n",
    "\n",
    "# ==================================================\n",
    "# ADDITIONAL FEATURES YOU CAN ADD:\n",
    "# ==================================================\n",
    "\n",
    "\"\"\"\n",
    "ðŸŽ¯ MORE ADVANCED FEATURES TO IMPLEMENT:\n",
    "\n",
    "1. REAL-TIME EMOTION RECOGNITION:\n",
    "  - Use TensorFlow/PyTorch emotion models\n",
    "  - Detect: Happy, Sad, Angry, Surprised, Fearful, Disgusted, Neutral\n",
    "\n",
    "2. FACE RECOGNITION & IDENTIFICATION:\n",
    "  - Use face_recognition library\n",
    "  - Save known faces to database\n",
    "  - Real-time identification with names\n",
    "\n",
    "3. ADVANCED AR FILTERS:\n",
    "  - Load custom 3D models\n",
    "  - Animal face morphing\n",
    "  - Background replacement (green screen effect)\n",
    "\n",
    "4. GESTURE-CONTROLLED INTERFACE:\n",
    "  - Hand tracking with MediaPipe\n",
    "  - Control filters with hand gestures\n",
    "  - Voice commands integration\n",
    "\n",
    "5. SOCIAL MEDIA INTEGRATION:\n",
    "  - Save filtered photos/videos\n",
    "  - Share to Instagram/TikTok\n",
    "  - Live streaming with filters\n",
    "\n",
    "6. PERFORMANCE ANALYTICS:\n",
    "  - Face detection accuracy metrics\n",
    "  - FPS optimization\n",
    "  - Memory usage monitoring\n",
    "\n",
    "7. MULTI-PERSON FEATURES:\n",
    "  - Individual filters per person\n",
    "  - Face swapping between people\n",
    "  - Group photo enhancements\n",
    "\n",
    "To implement these, install additional packages:\n",
    "pip install face-recognition tensorflow torch ultralytics\n",
    "pip install streamlit (for web interface)\n",
    "pip install opencv-contrib-python (for advanced features)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c973eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Age/Gender Detection Setup\n",
      "Choose an option:\n",
      "1. Download models and run detection\n",
      "2. Run with fallback detection (no download needed)\n",
      "ðŸ”„ Using fallback detection...\n",
      "âœ… Age/Gender models loaded successfully!\n",
      "âœ… Models tested successfully!\n",
      "ðŸŽ¯ Age/Gender Detection Started!\n",
      "Press 'q' to quit\n",
      "ðŸ’¡ To run simple estimation without downloads: simple_age_gender_estimation()\n"
     ]
    }
   ],
   "source": [
    "# AGE/GENDER MODEL SETUP - COMPLETE SOLUTION\n",
    "# This will automatically download and set up the required models\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "class AgeGenderModelDownloader:\n",
    "    def __init__(self):\n",
    "        self.model_urls = {\n",
    "            # Age detection model files\n",
    "            'age_weights': 'https://github.com/opencv/opencv_extra/raw/master/testdata/dnn/age_net.caffemodel',\n",
    "            'age_config': 'https://github.com/opencv/opencv_extra/raw/master/testdata/dnn/age_deploy.prototxt',\n",
    "            \n",
    "            # Gender detection model files  \n",
    "            'gender_weights': 'https://github.com/opencv/opencv_extra/raw/master/testdata/dnn/gender_net.caffemodel',\n",
    "            'gender_config': 'https://github.com/opencv/opencv_extra/raw/master/testdata/dnn/gender_deploy.prototxt'\n",
    "        }\n",
    "        \n",
    "        self.model_files = {\n",
    "            'age_weights': 'age_net.caffemodel',\n",
    "            'age_config': 'age_deploy.prototxt', \n",
    "            'gender_weights': 'gender_net.caffemodel',\n",
    "            'gender_config': 'gender_deploy.prototxt'\n",
    "        }\n",
    "        \n",
    "        # Create models directory\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    def download_model_file(self, url, filename):\n",
    "        \"\"\"Download a single model file\"\"\"\n",
    "        filepath = os.path.join('models', filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"âœ… {filename} already exists\")\n",
    "            return True\n",
    "            \n",
    "        try:\n",
    "            print(f\"â¬‡ï¸ Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(f\"âœ… Downloaded {filename} successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error downloading {filename}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def download_all_models(self):\n",
    "        \"\"\"Download all required model files\"\"\"\n",
    "        print(\"ðŸ¤– Downloading Age/Gender Detection Models...\")\n",
    "        print(\"This may take a few minutes depending on your internet speed.\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        success_count = 0\n",
    "        for key, url in self.model_urls.items():\n",
    "            filename = self.model_files[key]\n",
    "            if self.download_model_file(url, filename):\n",
    "                success_count += 1\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        if success_count == len(self.model_urls):\n",
    "            print(\"ðŸŽ‰ All models downloaded successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âš ï¸ Only {success_count}/{len(self.model_urls)} models downloaded\")\n",
    "            return False\n",
    "\n",
    "# IMPROVED AGE/GENDER DETECTOR WITH AUTO-DOWNLOAD\n",
    "class ImprovedAgeGenderDetector:\n",
    "    def __init__(self):\n",
    "        self.age_net = None\n",
    "        self.gender_net = None\n",
    "        self.age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "        self.gender_list = ['Male', 'Female']\n",
    "        \n",
    "        # Automatically download and load models\n",
    "        self.setup_models()\n",
    "    \n",
    "    def setup_models(self):\n",
    "        \"\"\"Setup models with automatic download\"\"\"\n",
    "        # Check if models exist, download if needed\n",
    "        model_files = [\n",
    "            'models/age_net.caffemodel',\n",
    "            'models/age_deploy.prototxt',\n",
    "            'models/gender_net.caffemodel', \n",
    "            'models/gender_deploy.prototxt'\n",
    "        ]\n",
    "        \n",
    "        models_exist = all(os.path.exists(f) for f in model_files)\n",
    "        \n",
    "        if not models_exist:\n",
    "            print(\"ðŸ“¦ Age/Gender models not found. Downloading...\")\n",
    "            downloader = AgeGenderModelDownloader()\n",
    "            if not downloader.download_all_models():\n",
    "                print(\"âŒ Failed to download models. Using fallback method.\")\n",
    "                self.create_fallback_detector()\n",
    "                return\n",
    "        \n",
    "        try:\n",
    "            # Load the models\n",
    "            self.age_net = cv2.dnn.readNet('models/age_net.caffemodel', 'models/age_deploy.prototxt')\n",
    "            self.gender_net = cv2.dnn.readNet('models/gender_net.caffemodel', 'models/gender_deploy.prototxt')\n",
    "            print(\"âœ… Age/Gender models loaded successfully!\")\n",
    "            \n",
    "            # Test the models\n",
    "            self.test_models()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading models: {e}\")\n",
    "            self.create_fallback_detector()\n",
    "    \n",
    "    def test_models(self):\n",
    "        \"\"\"Test if models are working correctly\"\"\"\n",
    "        try:\n",
    "            # Create a dummy input to test models\n",
    "            dummy_blob = cv2.dnn.blobFromImage(\n",
    "                np.zeros((100, 100, 3), dtype=np.uint8), \n",
    "                1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746)\n",
    "            )\n",
    "            \n",
    "            # Test age model\n",
    "            self.age_net.setInput(dummy_blob)\n",
    "            age_result = self.age_net.forward()\n",
    "            \n",
    "            # Test gender model  \n",
    "            self.gender_net.setInput(dummy_blob)\n",
    "            gender_result = self.gender_net.forward()\n",
    "            \n",
    "            print(\"âœ… Models tested successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Model test failed: {e}\")\n",
    "    \n",
    "    def create_fallback_detector(self):\n",
    "        \"\"\"Create a simple fallback detector using basic image analysis\"\"\"\n",
    "        print(\"ðŸ”„ Creating fallback age/gender detector...\")\n",
    "        self.use_fallback = True\n",
    "    \n",
    "    def predict_age_gender_fallback(self, face_roi):\n",
    "        \"\"\"Fallback method using simple image analysis\"\"\"\n",
    "        # Simple heuristic based on face characteristics\n",
    "        gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate average brightness (very simple heuristic)\n",
    "        avg_brightness = np.mean(gray_face)\n",
    "        \n",
    "        # Calculate texture (roughness indicator)\n",
    "        laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()\n",
    "        \n",
    "        # Simple age estimation based on texture\n",
    "        if laplacian_var > 500:\n",
    "            age = \"(25-32)\"  # High texture = adult\n",
    "        elif laplacian_var > 200:\n",
    "            age = \"(15-20)\"  # Medium texture = young adult  \n",
    "        else:\n",
    "            age = \"(8-12)\"   # Low texture = child\n",
    "        \n",
    "        # Simple gender estimation (very basic, not accurate)\n",
    "        gender = \"Male\" if avg_brightness < 120 else \"Female\"\n",
    "        \n",
    "        return age, gender, 0.5  # Low confidence for fallback\n",
    "    \n",
    "    def predict_age_gender(self, face_roi):\n",
    "        \"\"\"Predict age and gender for a face region\"\"\"\n",
    "        if face_roi is None or face_roi.size == 0:\n",
    "            return \"Unknown\", \"Unknown\", 0.0\n",
    "        \n",
    "        # Use fallback if models not available\n",
    "        if hasattr(self, 'use_fallback'):\n",
    "            return self.predict_age_gender_fallback(face_roi)\n",
    "        \n",
    "        if self.age_net is None or self.gender_net is None:\n",
    "            return \"Model Error\", \"Model Error\", 0.0\n",
    "        \n",
    "        try:\n",
    "            # Preprocess the face\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                face_roi, 1.0, (227, 227), \n",
    "                (78.4263377603, 87.7689143744, 114.895847746)\n",
    "            )\n",
    "            \n",
    "            # Age prediction\n",
    "            self.age_net.setInput(blob)\n",
    "            age_predictions = self.age_net.forward()\n",
    "            age_idx = age_predictions[0].argmax()\n",
    "            age_confidence = age_predictions[0].max()\n",
    "            predicted_age = self.age_list[age_idx]\n",
    "            \n",
    "            # Gender prediction\n",
    "            self.gender_net.setInput(blob)\n",
    "            gender_predictions = self.gender_net.forward()\n",
    "            gender_idx = gender_predictions[0].argmax()\n",
    "            gender_confidence = gender_predictions[0].max()\n",
    "            predicted_gender = self.gender_list[gender_idx]\n",
    "            \n",
    "            # Average confidence\n",
    "            avg_confidence = (age_confidence + gender_confidence) / 2\n",
    "            \n",
    "            return predicted_age, predicted_gender, avg_confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            return \"Error\", \"Error\", 0.0\n",
    "\n",
    "# COMPLETE FACE DETECTION WITH AGE/GENDER\n",
    "class CompleteFaceDetector:\n",
    "    def __init__(self):\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.age_gender_detector = ImprovedAgeGenderDetector()\n",
    "        \n",
    "    def detect_with_age_gender(self, frame):\n",
    "        \"\"\"Detect faces and predict age/gender\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face region\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Predict age and gender\n",
    "            age, gender, confidence = self.age_gender_detector.predict_age_gender(face_roi)\n",
    "            \n",
    "            results.append({\n",
    "                'bbox': (x, y, w, h),\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "            \n",
    "            # Draw results on frame\n",
    "            self.draw_results(frame, x, y, w, h, age, gender, confidence)\n",
    "        \n",
    "        return frame, results\n",
    "    \n",
    "    def draw_results(self, frame, x, y, w, h, age, gender, confidence):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        # Draw face rectangle\n",
    "        color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        \n",
    "        # Draw age and gender text\n",
    "        text = f\"{gender}, {age}\"\n",
    "        cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Draw confidence if available\n",
    "        if confidence > 0:\n",
    "            conf_text = f\"Conf: {confidence:.2f}\"\n",
    "            cv2.putText(frame, conf_text, (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "\n",
    "# DEMO APPLICATION\n",
    "def run_age_gender_detection():\n",
    "    \"\"\"Run the complete age/gender detection demo\"\"\"\n",
    "    detector = CompleteFaceDetector()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print(\"ðŸŽ¯ Age/Gender Detection Started!\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect faces with age/gender\n",
    "        frame, results = detector.detect_with_age_gender(frame)\n",
    "        \n",
    "        # Display statistics\n",
    "        cv2.putText(frame, f\"Faces detected: {len(results)}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Age/Gender Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# MANUAL MODEL DOWNLOAD FUNCTION (Alternative method)\n",
    "def download_models_manual():\n",
    "    \"\"\"Manual model download with progress tracking\"\"\"\n",
    "    print(\"ðŸ”§ Manual Model Download\")\n",
    "    print(\"If automatic download fails, you can:\")\n",
    "    print(\"1. Visit: https://github.com/opencv/opencv_extra/tree/master/testdata/dnn\")\n",
    "    print(\"2. Download these files:\")\n",
    "    print(\"   - age_net.caffemodel\")\n",
    "    print(\"   - age_deploy.prototxt\") \n",
    "    print(\"   - gender_net.caffemodel\")\n",
    "    print(\"   - gender_deploy.prototxt\")\n",
    "    print(\"3. Place them in a 'models' folder\")\n",
    "    print()\n",
    "    \n",
    "    # Try automatic download\n",
    "    downloader = AgeGenderModelDownloader()\n",
    "    success = downloader.download_all_models()\n",
    "    \n",
    "    if success:\n",
    "        print(\"âœ… Ready to use age/gender detection!\")\n",
    "    else:\n",
    "        print(\"âŒ Please download models manually using the links above\")\n",
    "\n",
    "# USAGE EXAMPLES\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ Age/Gender Detection Setup\")\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Download models and run detection\")\n",
    "    print(\"2. Run with fallback detection (no download needed)\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        download_models_manual()\n",
    "        run_age_gender_detection()\n",
    "    else:\n",
    "        print(\"ðŸ”„ Using fallback detection...\")\n",
    "        run_age_gender_detection()\n",
    "\n",
    "# Alternative: Simple age/gender estimation without deep learning models\n",
    "def simple_age_gender_estimation():\n",
    "    \"\"\"\n",
    "    Simple demonstration without requiring model downloads\n",
    "    Uses basic image analysis - not very accurate but works immediately\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¯ Simple Age/Gender Estimation (No models required)\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Very simple heuristics (not accurate, just for demo)\n",
    "            avg_color = np.mean(face_roi)\n",
    "            face_height_ratio = h / w\n",
    "            \n",
    "            # Simple age estimation based on face proportions\n",
    "            if face_height_ratio > 1.3:\n",
    "                age_est = \"Adult\"\n",
    "            elif face_height_ratio > 1.1:\n",
    "                age_est = \"Teen\"\n",
    "            else:\n",
    "                age_est = \"Child\"\n",
    "            \n",
    "            # Simple gender estimation (very basic)\n",
    "            gender_est = \"Male\" if avg_color < 120 else \"Female\"\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"{gender_est}, {age_est}\", (x, y-10), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Simple Age/Gender Estimation', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(\"ðŸ’¡ To run simple estimation without downloads: simple_age_gender_estimation()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
